{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Mean/Covariance of a data set and effect of a linear transformation\n",
    "\n",
    "In this week, we are going to investigate how the mean and (co)variance of a dataset changes\n",
    "when we apply affine transformation to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "1. Get Farmiliar with basic programming using Python and Numpy/Scipy.\n",
    "2. Learn to appreciate implementing\n",
    "   functions to compute statistics of dataset in vectorized way.\n",
    "3. Understand the effects of affine transformations on a dataset.\n",
    "4. Understand the importance of testing in programming for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the packages that we will use for the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGE: DO NOT EDIT\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('fivethirtyeight')\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import time\n",
    "import timeit\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to retrieve Olivetti faces dataset.\n",
    "\n",
    "When working with some datasets, before digging into further analysis, it is almost always\n",
    "useful to do a few things to understand your dataset. First of all, answer the following\n",
    "set of questions:\n",
    "\n",
    "1. What is the size of your dataset?\n",
    "2. What is the dimensionality of your data?\n",
    "\n",
    "The dataset we have are usually stored as 2D matrices, then it would be really important\n",
    "to know which dimension represents the dimension of the dataset, and which represents\n",
    "the data points in the dataset. \n",
    "\n",
    "__When you implement the functions for your assignment, make sure you read\n",
    "the docstring for what each dimension of your inputs represents the data points, and which \n",
    "represents the dimensions of the dataset!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to ./\n",
      "Shape of the faces dataset: (400, 4096)\n",
      "400 data points\n"
     ]
    }
   ],
   "source": [
    "image_shape = (64, 64)\n",
    "# Load faces data\n",
    "dataset = fetch_olivetti_faces(data_home='./')\n",
    "faces = dataset.data\n",
    "\n",
    "print('Shape of the faces dataset: {}'.format(faces.shape))\n",
    "print('{} data points'.format(faces.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your dataset are images, it's a really good idea to see what they look like.\n",
    "\n",
    "One very\n",
    "convenient tool in Jupyter is the `interact` widget, which we use to visualize the images (faces). For more information on how to use interact, have a look at the documentation [here](http://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_face(face):\n",
    "    plt.figure()\n",
    "    plt.imshow(face.reshape((64, 64)), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a0c957c4474c1f97a083450d5c382c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=399), Output()), _dom_classes=('widget-interact'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(n=(0, len(faces)-1))\n",
    "def display_faces(n=0):\n",
    "    plt.figure()\n",
    "    plt.imshow(faces[n].reshape((64, 64)), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mean and Covariance of a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "def mean_naive(X):\n",
    "    \"\"\"Compute the sample mean for a dataset by iterating over the dataset.\n",
    "    \n",
    "    Args:\n",
    "        X: `ndarray` of shape (N, D) representing the dataset. N \n",
    "        is the size of the dataset and D is the dimensionality of the dataset.\n",
    "    Returns:\n",
    "        mean: `ndarray` of shape (D, ), the sample mean of the dataset `X`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "#     iterate over the dataset and compute the mean vector.\n",
    "    N, D = X.shape\n",
    "    mean = np.zeros((D,))\n",
    "\n",
    "    for n in range(N):\n",
    "        # Update the mean vector\n",
    "        mean = mean + (X[n-1])/N\n",
    "    return mean\n",
    "\n",
    "def cov_naive(X):\n",
    "    \"\"\"Compute the sample covariance for a dataset by iterating over the dataset.\n",
    "    \n",
    "    Args:\n",
    "        X: `ndarray` of shape (N, D) representing the dataset. N \n",
    "        is the size of the dataset and D is the dimensionality of the dataset.\n",
    "    Returns:\n",
    "        ndarray: ndarray with shape (D, D), the sample covariance of the dataset `X`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "    N, D = X.shape\n",
    "    ### Edit the code below to compute the covariance matrix by iterating over the dataset.\n",
    "    covariance = np.zeros((D, D))\n",
    "    ### Update covariance\n",
    "    diff = np.zeros((N,D))\n",
    "    d = 0\n",
    "    for n in range(N):\n",
    "        # Update the mean vector\n",
    "        diff[d] = diff[d] + (X[n-1]-mean_naive(X))\n",
    "        d += 1\n",
    "\n",
    "    covariance = (diff.T@diff)/N\n",
    "    ###\n",
    "    return covariance\n",
    "\n",
    "def mean(X):\n",
    "    \"\"\"Compute the sample mean for a dataset.\n",
    "    \n",
    "    Args:\n",
    "        X: `ndarray` of shape (N, D) representing the dataset. N \n",
    "        is the size of the dataset and D is the dimensionality of the dataset.\n",
    "    Returns:\n",
    "        ndarray: ndarray with shape (D,), the sample mean of the dataset `X`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "    N, D = X.shape\n",
    "    m = np.zeros((X.shape[1]))\n",
    "    m = (m + sum(X))/N\n",
    "    return m\n",
    "\n",
    "def cov(X):\n",
    "    \"\"\"Compute the sample covariance for a dataset.\n",
    "    \n",
    "    Args:\n",
    "        X: `ndarray` of shape (N, D) representing the dataset. N \n",
    "        is the size of the dataset and D is the dimensionality of the dataset.\n",
    "    Returns:\n",
    "        ndarray: ndarray with shape (D, D), the sample covariance of the dataset `X`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # It is possible to vectorize our code for computing the covariance with matrix multiplications,\n",
    "    # i.e., we do not need to explicitly\n",
    "    # iterate over the entire dataset as looping in Python tends to be slow\n",
    "    # We challenge you to give a vectorized implementation without using np.cov, but if you choose to use np.cov,\n",
    "    # be sure to pass in bias=True.\n",
    "    ### Uncomment and edit the code below\n",
    "    N, D = X.shape\n",
    "    ### Edit the code to compute the covariance matrix\n",
    "    covariance_matrix = np.zeros((D, D))\n",
    "    diff = np.zeros((N,D))\n",
    "    ### Update covariance_matrix here\n",
    "    diff = diff + (X-mean(X))\n",
    "    covariance_matrix = (diff.T@diff)/N\n",
    "    ###\n",
    "    return covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 1.5 1. ]\n",
      "[1.  2.  0.5]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "\n",
    "# Test case 1\n",
    "X = np.array([[0., 1., 1.], \n",
    "              [1., 2., 1.]])\n",
    "expected_mean = np.array([0.5, 1.5, 1.])\n",
    "assert_allclose(mean(X), expected_mean, rtol=1e-5)\n",
    "print(mean(X))\n",
    "\n",
    "# Test case 2\n",
    "X = np.array([[0., 1., 0.], \n",
    "              [2., 3., 1.]])\n",
    "expected_mean = np.array([1., 2., 0.5])\n",
    "assert_allclose(mean(X), expected_mean, rtol=1e-5)\n",
    "print(mean(X))\n",
    "\n",
    "# Test covariance is zero\n",
    "X = np.array([[0., 1.], \n",
    "              [0., 1.]])\n",
    "expected_mean = np.array([0., 1.])\n",
    "assert_allclose(mean(X), expected_mean, rtol=1e-5)\n",
    "print(mean(X))\n",
    "\n",
    "### Some hidden tests below\n",
    "### ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25 0.25]\n",
      " [0.25 0.25]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0., 1.], \n",
    "     [1., 2.],\n",
    "     [0., 1.], \n",
    "     [1., 2.]\n",
    "    ])\n",
    "\n",
    "print(cov(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25 0.25]\n",
      " [0.25 0.25]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "\n",
    "# Test case 1\n",
    "X = np.array([[0., 1.], \n",
    "              [1., 2.],\n",
    "     [0., 1.], \n",
    "     [1., 2.]])\n",
    "expected_cov = np.array(\n",
    "    [[0.25, 0.25],\n",
    "    [0.25, 0.25]])\n",
    "\n",
    "assert_allclose(cov(X), expected_cov, rtol=1e-5)\n",
    "print(cov(X))\n",
    "\n",
    "# Test case 2\n",
    "X = np.array([[0., 1.], \n",
    "              [2., 3.]])\n",
    "expected_cov = np.array(\n",
    "    [[1., 1.],\n",
    "    [1., 1.]])\n",
    "\n",
    "assert_allclose(cov(X), expected_cov, rtol=1e-5)\n",
    "print(cov(X))\n",
    "\n",
    "# Test covariance is zero\n",
    "X = np.array([[0., 1.], \n",
    "              [0., 1.],\n",
    "              [0., 1.]])\n",
    "expected_cov = np.zeros((2, 2))\n",
    "\n",
    "assert_allclose(cov(X), expected_cov, rtol=1e-5)\n",
    "print(cov(X))\n",
    "\n",
    "### Some hidden tests below\n",
    "### ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `mean` function implemented, let's take a look at the _mean_ face of our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mean_face(faces):\n",
    "    return faces.mean(axis=0).reshape((64, 64))\n",
    "\n",
    "plt.imshow(mean_face(faces), cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the advantage of writing vectorized code is speedup gained when working on larger dataset. Loops in Python\n",
    "are slow, and most of the time you want to utilise the fast native code provided by Numpy without explicitly using\n",
    "for loops. To put things into perspective, we can benchmark the two different implementation with the `%time` function\n",
    "in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "# We have some HUUUGE data matrix which we want to compute its mean\n",
    "X = np.random.randn(1000, 20)\n",
    "# Benchmarking time for computing mean\n",
    "%time mean_naive(X)\n",
    "%time mean(X)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.85 s\n",
      "Wall time: 1.02 ms\n"
     ]
    }
   ],
   "source": [
    "# Benchmarking time for computing covariance\n",
    "%time cov_naive(X)\n",
    "%time cov(X)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Affine Transformation of Dataset\n",
    "In this week we are also going to verify a few properties about the mean and\n",
    "covariance of affine transformation of random variables.\n",
    "\n",
    "Consider a data matrix $X$ of size (N, D). We would like to know\n",
    "what is the covariance when we apply affine transformation $Ax_i + b$ for each datapoint $x_i$ in $X$. i.e.\n",
    "we would like to know what happens to the mean and covariance for the new dataset if we apply affine transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "def affine_mean(mean, A, b):\n",
    "    \"\"\"Compute the mean after affine transformation\n",
    "    Args:\n",
    "        mean: `ndarray` of shape (D,), the sample mean vector for some dataset.\n",
    "        A, b: `ndarray` of shape (D, D) and (D,), affine transformation applied to x\n",
    "    Returns:\n",
    "        sample mean vector of shape (D,) after affine transformation.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "    ### Edit the code below to compute the mean vector after affine transformation\n",
    "    affine_m = np.zeros(mean.shape) # affine_m has shape (D,)\n",
    "    ### Update affine_m\n",
    "    affine_m = A@mean + b\n",
    "    ###\n",
    "    return affine_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "def affine_covariance(S, A, b):\n",
    "    \"\"\"Compute the covariance matrix after affine transformation\n",
    "    \n",
    "    Args:\n",
    "        mean: `ndarray` of shape (D,), the sample covariance matrix for some dataset.\n",
    "        A, b: `ndarray` of shape (D, D) and (D,), affine transformation applied to x\n",
    "    \n",
    "    Returns:\n",
    "        sample covariance matrix of shape (D, D) after the transformation\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "    ### EDIT the code below to compute the covariance matrix after affine transformation\n",
    "    affine_cov = np.zeros(S.shape) # affine_cov has shape (D, D)\n",
    "    ### Update affine_cov\n",
    "    affine_cov = A@S@A.T\n",
    "    ###\n",
    "    return affine_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3. 11.]\n",
      "[[ 2.  6.]\n",
      " [ 6. 26.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "\n",
    "A = np.array([[0, 1], [2, 3]])\n",
    "b = np.ones(2)\n",
    "m = np.full((2,), 2)\n",
    "S = np.eye(2)*2\n",
    "\n",
    "expected_affine_mean = np.array([ 3., 11.])\n",
    "expected_affine_cov = np.array(\n",
    "    [[ 2.,  6.],\n",
    "    [ 6., 26.]])\n",
    "\n",
    "assert_allclose(affine_mean(m, A, b), expected_affine_mean, rtol=1e-4)\n",
    "### Some hidden tests below\n",
    "### ...\n",
    "\n",
    "print(affine_mean(m, A, b))\n",
    "print(affine_covariance(S, A, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  6.]\n",
      " [ 6. 26.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "\n",
    "A = np.array([[0, 1], [2, 3]])\n",
    "b = np.ones(2)\n",
    "m = np.full((2,), 2)\n",
    "S = np.eye(2)*2\n",
    "\n",
    "expected_affine_cov = np.array(\n",
    "    [[ 2.,  6.],\n",
    "    [ 6., 26.]])\n",
    "\n",
    "assert_allclose(affine_covariance(S, A, b), \n",
    "                expected_affine_cov, rtol=1e-4)\n",
    "\n",
    "### Some hidden tests below\n",
    "### ...\n",
    "print(affine_covariance(S, A, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the two functions above are implemented, we can verify the correctness our implementation. Assuming that we have some $A$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = np.random.RandomState(42)\n",
    "A = random.randn(4,4)\n",
    "b = random.randn(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can generate some random dataset $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = random.randn(100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that for some dataset $X$, the mean and covariance are $m$, $S$, and for the new dataset after affine transformation $X'$, the mean and covariance are $m'$ and $S'$, then we would have the following identity:\n",
    "\n",
    "$$m' = \\text{affine_mean}(m, A, b)$$\n",
    "\n",
    "$$S' = \\text{affine_covariance}(S, A, b)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = ((A @ (X.T)).T + b)  # applying affine transformation once\n",
    "X2 = ((A @ (X1.T)).T + b) # twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very useful way to compare whether arrays are equal/similar is use the helper functions\n",
    "in `numpy.testing`.\n",
    "\n",
    "Check the Numpy [documentation](https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.testing.html)\n",
    "for details.\n",
    "\n",
    "If you are interested in learning more about floating point arithmetic, here is a good [paper](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.6768)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.96392872  0.39068793 -0.89457522 -1.63436635]\n",
      "[[ 2.54561012  1.7908973  -1.04371539 -1.60738612]\n",
      " [ 1.7908973   2.98978168 -1.0182833  -2.66670295]\n",
      " [-1.04371539 -1.0182833   0.79837594  0.03864156]\n",
      " [-1.60738612 -2.66670295  0.03864156  6.33460007]]\n"
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(mean(X1), affine_mean(mean(X), A, b))\n",
    "np.testing.assert_allclose(cov(X1),  affine_covariance(cov(X), A, b))\n",
    "\n",
    "print(affine_mean(mean(X), A, b))\n",
    "print(affine_covariance(cov(X), A, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.61424122 -2.21851414  0.93222245  0.06901898]\n",
      "[[13.74617313  8.89396021 -5.7104493   2.07227516]\n",
      " [ 8.89396021  9.3763118  -4.34089098  1.8017062 ]\n",
      " [-5.7104493  -4.34089098  2.79364942 -1.69475979]\n",
      " [ 2.07227516  1.8017062  -1.69475979  2.73824813]]\n"
     ]
    }
   ],
   "source": [
    "np.testing.assert_allclose(mean(X2), affine_mean(mean(X1), A, b))\n",
    "np.testing.assert_allclose(cov(X2),  affine_covariance(cov(X1), A, b))\n",
    "\n",
    "print(affine_mean(mean(X1), A, b))\n",
    "print(affine_covariance(cov(X1), A, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
